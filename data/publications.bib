
@inproceedings{yuanHalftoningBasedFragileWatermarking2022,
	title = {Halftoning-{Based} {Fragile} {Watermarking} {Approach} for {Digital} {Image} {Self}-{Recovery}},
	doi = {10.1109/ICSIP55141.2022.9886130},
	abstract = {This paper proposes a halftoning-based fragile watermarking approach for digital image tamper detection and self-recovery. The Set Partitioning in Hierarchical Trees (SPIHT) algorithm and halftoning technique are employed to generate the primary recovery bits and secondary recovery bits, respectively. On basis of that, the authentication bits are generated. The Arnold Cat Map and diagonal mapping are then applied to further improve the accuracy of tamper detection and ensure the quality of self-recovery. The experimental results have been conducted to demonstrate the superiorities of the proposed approach in imperceptibility and recovery capability.},
	booktitle = {2022 7th {International} {Conference} on {Signal} and {Image} {Processing} ({ICSIP})},
	author = {Yuan, Xiaochen and Zhang, Qiyuan},
	month = jul,
	year = {2022},
	keywords = {Arnold cat map, Authentication, Digital images, halftoning technique, Image processing, Partitioning algorithms, Set Partitioning in Hierarchical Trees (SPIHT), tamper detection, Watermarking},
	pages = {352--355},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/XNGIJC5T/9886130.html:text/html;Yuan_Zhang_2022_Halftoning-Based Fragile Watermarking Approach for Digital Image Self-Recovery.pdf:/Users/maodou/Zotero/storage/UAG6QAHC/Yuan_Zhang_2022_Halftoning-Based Fragile Watermarking Approach for Digital Image Self-Recovery.pdf:application/pdf},
}

@inproceedings{zhangRecognitionScoreWord2022,
	title = {Recognition of {Score} {Word} in {Freestyle} {Kayaking}},
	doi = {10.1109/ICEIEC54567.2022.9835045},
	abstract = {Speech is the most natural information carrier for human beings, and it is likely to become the main way of human-computer interaction in the future. This paper presents an isolated score word recognition method using Mel-scale Frequency Cepstral Coefficients (MFCC) and Dynamic Time Warping (DTW). The processing stage of the speech signal is the basic stage of the speech recognition system, to analyze the speech signal and convert it into speech feature parameters. An endpoints detection method is proposed using the joint adjustment of short-term energy and zero-crossing rate. It can better detect the endpoints, and directly improve the accuracy of subsequent work. On this basis, the MFCC feature is then extracted from the preprocessed speech signal, and the DTW pattern matching is applied to the extracted features. In the experiments, speeches from multiple speakers were collected, each with a specific freestyle kayak action word. The results show that this method has better performance comparing with the existing methods.},
	booktitle = {2022 {IEEE} 12th {International} {Conference} on {Electronics} {Information} and {Emergency} {Communication} ({ICEIEC})},
	author = {Zhang, Qiyuan and Yuan, Xiaochen and Lam, Chan Tong},
	month = jul,
	year = {2022},
	note = {ISSN: 2377-844X},
	keywords = {Conferences, Databases, Dynamic Time Warping, End Point Detection, Feature extraction, Freestyle Kayaking, Human computer interaction, Mel-scale Frequency Cepstral Coefficients, Speech recognition, Time-frequency analysis, Training},
	pages = {67--70},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/ALNX7UAX/9835045.html:text/html;Zhang et al_2022_Recognition of Score Word in Freestyle Kayaking.pdf:/Users/maodou/Zotero/storage/8RLQF5JB/Zhang et al_2022_Recognition of Score Word in Freestyle Kayaking.pdf:application/pdf},
}

@inproceedings{yuanReversibleMultiLevelWatermarking2022,
	title = {Reversible {Multi}-{Level} {Watermarking} {Scheme} for {Color} {Images}},
	doi = {10.1109/ICEIEC54567.2022.9835083},
	abstract = {Reversible data hiding is to embed data into digital multimedia, while the original multimedia and embedded data can be restored from the watermarked one without any loss. In this paper, we propose a novel Reversible Multi-Level Watermarking (RMLW) scheme for color images with grayscale invariance. Being different from the traditional reversible data hiding methods, we adapt the gray scale-invariant reversible watermarking method which keeps the grayscale of image unchanged as the information is embedded. In the RMLW, one feature region of high robustness is extracted and into which the watermarks are then embedded for multiple times. Lots of experiments have been conducted and the results show that the proposed scheme can extend the capacity efficiently while keep the characteristic of grayscale invariance.},
	booktitle = {2022 {IEEE} 12th {International} {Conference} on {Electronics} {Information} and {Emergency} {Communication} ({ICEIEC})},
	author = {Yuan, Xiaochen and Sun, Ying},
	month = jul,
	year = {2022},
	note = {ISSN: 2377-844X},
	keywords = {Color, Conferences, Feature extraction, Gray scale-invariant, Gray-scale, Histograms, Reversible data hiding, Reversible Multi-Level Watermarking (RMLW), Robustness, Watermarking},
	pages = {9--12},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/U8BSVQ7I/9835083.html:text/html;Yuan_Sun_2022_Reversible Multi-Level Watermarking Scheme for Color Images.pdf:/Users/maodou/Zotero/storage/GPTYH8YR/Yuan_Sun_2022_Reversible Multi-Level Watermarking Scheme for Color Images.pdf:application/pdf},
}

@inproceedings{yuanDualPartialRecurrent2021,
	address = {Sanya China},
	title = {Dual {Partial} {Recurrent} {Networks} for {Hyperspectral} {Image} {Change} {Detection}},
	isbn = {978-1-4503-8505-3},
	url = {https://dl.acm.org/doi/10.1145/3508546.3508616},
	doi = {10.1145/3508546.3508616},
	abstract = {This paper presents a Dual Partial Recurrent Networks (DUALPRNs) which can project more accurate and effective image features by learning invariant pixel pairs with high confidence. The Change Vector Analysis provides a reference for the model to select invariant pixel pairs with high confidence as training samples. Then, the Unsupervised Slow Feature Analysis (USFA) is utilized to suppress the invariant pixel features projected by DUAL-PRNs, and highlight the variant pixel features, respectively. Thus, more obvious discrimination between the invariant and variant pixels can be achieved. Two groups of features are then obtained by passing bi-temporal remote sensing images through DUAL-PRNs and USFA. Chi-square distance is employed to calculate the divergence between two groups of features and thus generate the Change Intensity Map. Finally, the thresholding algorithm transforms the change intensity map into binary change map. Experimental results show that the proposed change detection model DUAL-PRNs performs better than the advanced model DSFA-128-2.},
	language = {en},
	urldate = {2022-11-01},
	booktitle = {2021 4th {International} {Conference} on {Algorithms}, {Computing} and {Artificial} {Intelligence}},
	publisher = {ACM},
	author = {Yuan, Xiaochen and Li, Jinlong},
	month = dec,
	year = {2021},
	pages = {1--7},
	file = {Yuan 和 Li - 2021 - Dual Partial Recurrent Networks for Hyperspectral .pdf:/Users/maodou/Zotero/storage/IPKJMQWE/Yuan 和 Li - 2021 - Dual Partial Recurrent Networks for Hyperspectral .pdf:application/pdf},
}

@inproceedings{liuImageSelfRecoveryBased2020a,
	title = {Image {Self}-{Recovery} {Based} on {Authentication} {Feature} {Extraction}},
	doi = {10.1109/TrustCom50675.2020.00164},
	abstract = {This paper proposes a novel image self-recovery scheme based on authentication feature extraction. The Authentication Feature Extraction method is proposed to calculate the authentication information. The Set Partitioning in Hierarchical Trees encoding algorithm is employed to calculate the recovery information. Moreover, in order to retrieve the damaged information caused by tampering, we propose to map each block into another position and generate the mapped-recovery information accordingly. In this way, a double assurance of recovery information can be provided. Experimental results show the superior performance of the proposed scheme in terms of image self-recovery. Comparison with the state-of-the-art works demonstrate that the proposed scheme shows efficiency in strong capability for image recovery, and effectiveness of attack resistance.},
	booktitle = {2020 {IEEE} 19th {International} {Conference} on {Trust}, {Security} and {Privacy} in {Computing} and {Communications} ({TrustCom})},
	author = {Liu, Tong and Yuan, Xiaochen},
	month = dec,
	year = {2020},
	note = {ISSN: 2324-9013},
	keywords = {Authentication, Authentication Feature Extraction, Authentication Information, Encoding, Feature extraction, Image Self-Recovery, Partitioning algorithms, Privacy, Recovery Information, Resistance, Set Partitioning in Hierarchical Trees, Watermarking},
	pages = {1222--1227},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/F5ADPE2E/9343106.html:text/html;Liu_Yuan_2020_Image Self-Recovery Based on Authentication Feature Extraction.pdf:/Users/maodou/Zotero/storage/JG5AW9QH/Liu_Yuan_2020_Image Self-Recovery Based on Authentication Feature Extraction.pdf:application/pdf},
}

@inproceedings{fuCompositeFeatureExtraction2020a,
	title = {Composite {Feature} {Extraction} for {Speech} {Emotion} {Recognition}},
	doi = {10.1109/CSE50738.2020.00018},
	abstract = {This paper proposes an approach for speech emotion recognition based on the composite feature extraction. The traditional paralinguistic and prosodic features and the neurogram features are extracted and concatenated together to be the composite feature. The neural feature is presented by a computational model which outputs a series of responses of a speech's particular characteristic frequency through auditory nerve fiber. The exported responses signals are visualized as the 2D neurogram and then extracted as neural feature. With the extracted composite feature, support vector machines is used to classify the emotion. The eNTERFACE database is used and the various metrics are calculated to evaluate the performance of the proposed approach. Experimental results show that the proposed approach achieves good performances under different conditions and performs better than the related work in terms of the various evaluation metrics.},
	booktitle = {2020 {IEEE} 23rd {International} {Conference} on {Computational} {Science} and {Engineering} ({CSE})},
	author = {Fu, Yangzhi and Yuan, Xiaochen},
	month = dec,
	year = {2020},
	keywords = {Composite Feature Extraction, Databases, Emotion recognition, Feature extraction, Neurogram Features, Noise measurement, Paralinguistic and Prosodic Features, Speech Emotion Classification, Speech recognition, Support Vector Machine, Two dimensional displays, Visualization},
	pages = {72--77},
	file = {Fu_Yuan_2020_Composite Feature Extraction for Speech Emotion Recognition.pdf:/Users/maodou/Zotero/storage/AILWLVA3/Fu_Yuan_2020_Composite Feature Extraction for Speech Emotion Recognition.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/KWTX8FE5/9345919.html:text/html},
}

@inproceedings{chenAudioAmplitudeLevelQuantification2018,
	title = {Audio {Amplitude}-{Level} {Quantification} {Vector} for {Identification} of {Audio} {Post}-{Processing} {Operation}},
	doi = {10.1109/SNSP.2018.00050},
	abstract = {Audio tampering is typically followed by post-processing operations to mask the artifacts potentially perceptible by human ears and blur the traces of tampering. However, research on the issue of audio post-processing identification is still a blanket. This paper mainly introduces a method to identify audio post-processing operations. A new audio feature - Audio Amplitude-Level Quantification Vector (AQV) is proposed, then the probability distributions of AQV of audio are calculated and extracted as audio features which are then used for identification of various audio processing. During the detection, the K-Nearest Neighbors (KNN) classifier is applied for classification. Experimental results show that the proposed AQV method can not only verify the authenticity of the speech audio, but also have a significant effect on identifying different types of post-processing operations.},
	booktitle = {2018 {International} {Conference} on {Sensor} {Networks} and {Signal} {Processing} ({SNSP})},
	author = {Chen, Zekun and Yuan, Xiaochen},
	month = oct,
	year = {2018},
	keywords = {Audio Amplitude-Level Quantification Vector (AQV), Audio Feature, Audio Post-processing Detection, Classification algorithms, Digital audio players, Feature extraction, Gold, K-Nearest Neighbors (KNN), Support vector machines, Testing, Training},
	pages = {226--230},
	file = {Chen_Yuan_2018_Audio Amplitude-Level Quantification Vector for Identification of Audio.pdf:/Users/maodou/Zotero/storage/87ZHP933/Chen_Yuan_2018_Audio Amplitude-Level Quantification Vector for Identification of Audio.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/9NULFB62/8615928.html:text/html},
}

@inproceedings{huangDetectionClassificationVarious2018,
	title = {Detection {And} {Classification} {Of} {Various} {Image} {Operations} {Using} {Deep} {Learning} {Technology}},
	volume = {1},
	doi = {10.1109/ICMLC.2018.8526999},
	abstract = {As one of the main medium for information transmission, the digital imagecan be easily tampered during transmission. It is becoming more and more important to identifywhether the given image is an original image or a processed image. In this paper, we propose acompact universal feature based on spatial domain in virtue of some latest image forensic methods and design a multi-class classification scheme using the deep learning technique, to identify and furthermore classify the various normal image operations. According to the experimental results, the proposed method can well detect and classify the multiple common image post-processing operations. And the comparison with the existing feature shows the better performance of the proposed method.},
	booktitle = {2018 {International} {Conference} on {Machine} {Learning} and {Cybernetics} ({ICMLC})},
	author = {HUANG, TIAN and YUAN, XIAOCHEN},
	month = jul,
	year = {2018},
	note = {ISSN: 2160-1348},
	keywords = {Convolution, Convolutional neural network (CNN), Deep learning technique, Digital images, Feature extraction, Filtering, Image coding, Image post-processing Operations detection, Quantization (signal), Spatial rich model (SRM)},
	pages = {50--55},
	file = {HUANG_YUAN_2018_Detection And Classification Of Various Image Operations Using Deep Learning.pdf:/Users/maodou/Zotero/storage/FINABRRA/HUANG_YUAN_2018_Detection And Classification Of Various Image Operations Using Deep Learning.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/LY5S67KR/8526999.html:text/html},
}

@inproceedings{liImageQualityEstimation2018,
	title = {Image {Quality} {Estimation} {Using} {Logarithmic} {Spread} {Transform} {Dither} {Modulation}},
	volume = {1},
	doi = {10.1109/ICMLC.2018.8526945},
	abstract = {As a pragmatic and novel application of digital watermarking, image quality estimation has been studied in recent years. In this paper, we propose a watermarking-based image quality evaluation scheme. The Logarithmic Spread Transform Dither Modulation is proposed based on the quantization index modulation and then applied to embed and extract the watermarks. The traditional objective metrics are employed to measure quality of images. We calculate the True Detection Rates (TDR) value to represent degradation of watermark. Considering that the embedded watermark and the watermarked image are distorted simultaneously, the image quality can be evaluated by matching the TDR value with a quality value on a pre-generated curve. Experimental results indicate that the proposed scheme provides a good image quality estimation result. The accuracy of the estimation keeps stabilization under different tested attacks, including JPEG compression, Gaussian noise addition and low-pass filtering.},
	booktitle = {2018 {International} {Conference} on {Machine} {Learning} and {Cybernetics} ({ICMLC})},
	author = {Li, Na and Yuan, Xiaochen},
	month = jul,
	year = {2018},
	note = {ISSN: 2160-1348},
	keywords = {Estimation, Image quality, Image quality estimation, Logarithmic spread transform dither modulation, Measurement, Modulation, Quantization (signal), Quantization index modulation, Transform coding, True detection rates, Watermarking},
	pages = {282--287},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/82NWGCV4/8526945.html:text/html;Li_Yuan_2018_Image Quality Estimation Using Logarithmic Spread Transform Dither Modulation.pdf:/Users/maodou/Zotero/storage/5DYE6MDG/Li_Yuan_2018_Image Quality Estimation Using Logarithmic Spread Transform Dither Modulation.pdf:application/pdf},
}

@inproceedings{liRobustDigitalImage2018,
	title = {Robust digital image watermarking using distortion-compensated dither modulation},
	volume = {10615},
	booktitle = {Ninth {International} {Conference} on {Graphic} and {Image} {Processing} ({ICGIP} 2017)},
	publisher = {SPIE},
	author = {Li, Mianjie and Yuan, Xiaochen},
	year = {2018},
	pages = {1368--1375},
}

@inproceedings{zhanAudioPostprocessingDetection2017,
	title = {Audio post-processing detection and identification based on audio features},
	doi = {10.1109/ICWAPR.2017.8076681},
	abstract = {As an important communication medium, audios are easily modified or tampered during transmission; thus the authenticity of audios is of high importance. This paper mainly introduces a method to detect audio post-processing based on audio features; the Support Vector Machine (SVM) is applied for classification during the detection. In the proposed method, the Mel Frequency Cepstral Coefficient (MFCC) and the Linear Prediction Coding (LPC) of host audios are calculated as audio features, to which SVM is applied to judge the authenticity of the audios. Experimental results show that the proposed audio feature based method can not only verify the authenticity of speech audio, but also have a significant effect on detecting different types of post-processing operations.},
	booktitle = {2017 {International} {Conference} on {Wavelet} {Analysis} and {Pattern} {Recognition} ({ICWAPR})},
	author = {Zhan, Yunzhen and Yuan, Xiaochen},
	month = jul,
	year = {2017},
	note = {ISSN: 2158-5709},
	keywords = {Audio Feature, Audio Post-processing Detection, Cepstrum, Conferences, Linear Prediction Coding (LPC), Linear predictive coding, Mel frequency cepstral coefficient, Mel Frequency Cepstral Coefficient (MFCC), Multimedia communication, Signal processing, Support Vector Machine (SVM)},
	pages = {154--158},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/QD2PMAQQ/8076681.html:text/html;Zhan_Yuan_2017_Audio post-processing detection and identification based on audio features.pdf:/Users/maodou/Zotero/storage/UML5XPDY/Zhan_Yuan_2017_Audio post-processing detection and identification based on audio features.pdf:application/pdf},
}

@inproceedings{liRobustFeatureExtraction2017,
	title = {Robust {Feature} {Extraction} {Based} {Watermarking} {Method} {Using} {Spread} {Transform} {Dither} {Modulation}},
	doi = {10.1109/CMVIT.2017.11},
	abstract = {This paper proposes a local digital image watermarking method based on robust feature extraction. A robust feature extraction method is proposed based on DAISY to extract feature regions. Each feature region is decomposed into approximation and details sub-bands by wavelet transform and the watermark is then embedded into and/or extracted from the approximation coefficients. Spread Transform Dither Modulation is applied to embed and extract the watermark. Multiple copies of watermark images are embedded into the feature regions to increase the success rate of watermark extraction and meanwhile improve the robustness. Experimental results show the very good image quality of the watermarked image and the low Bit Error Rate of watermark extraction. Furthermore, the comparison results indicate the better performance and higher robustness of the proposed scheme when under various attacks comparing with the existing methods.},
	booktitle = {2017 {International} {Conference} on {Machine} {Vision} and {Information} {Technology} ({CMVIT})},
	author = {Li, Mianjie and Yuan, Xiaochen},
	month = feb,
	year = {2017},
	keywords = {Discrete wavelet transforms, Feature extraction, Information technology, Local Digital Image Watermarking, Modulation, Robust Feature Extraction, Robustness, Spread Transform Dither Modulation, Watermarking},
	pages = {18--22},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/3BKB3Z4G/7878648.html:text/html;Li_Yuan_2017_Robust Feature Extraction Based Watermarking Method Using Spread Transform.pdf:/Users/maodou/Zotero/storage/6AT26B63/Li_Yuan_2017_Robust Feature Extraction Based Watermarking Method Using Spread Transform.pdf:application/pdf},
}

@inproceedings{biAdaptivePolarBased2016,
	title = {Adaptive {Polar} {Based} {Filtering} {Method} for {Image} {Copy}-{Move} {Forgery} {Detection}},
	doi = {10.1109/TrustCom.2016.0161},
	abstract = {In this paper, an Adaptive Polar based Filtering Method is proposed for image copy-move forgery detection. In order to improve the performance of detection method, the post-processing of the matching results is worth being focused on. To filter out the redundant pixels from the initially matched pixels, two pixels sets-Symmetrical Matched Pixels set and Unsymmetrical Matched Pixels set, are extracted from the matched pixel pairs, furthermore, the polar distributions of the two sets are calculated respectively. Then, the filtering thresholds can be adaptively calculated according to the polar distribution, thus the redundant pixels can be filtered out accordingly. Finally, some morphological operations are applied to the remained pixels to generate the detected forged regions. Experimental results show that the proposed scheme can achieve much better detection results compared with the existing state-of-the-art copy-move forgery detection methods.},
	booktitle = {2016 {IEEE} {Trustcom}/{BigDataSE}/{ISPA}},
	author = {Bi, Xiuli and Pun, Chi-Man and Yuan, Xiao-Chen},
	month = aug,
	year = {2016},
	note = {ISSN: 2324-9013},
	keywords = {Adaptive Polar based Filtering Method, Copy-Move Forgery, Polar Distribution},
	pages = {952--956},
	file = {Bi et al_2016_Adaptive Polar Based Filtering Method for Image Copy-Move Forgery Detection.pdf:/Users/maodou/Zotero/storage/E5PIAS8C/Bi et al_2016_Adaptive Polar Based Filtering Method for Image Copy-Move Forgery Detection.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/JBM3DHGW/7847044.html:text/html},
}

@inproceedings{yanAdaptiveLocalFeature2015,
	title = {Adaptive local feature based multi-scale image hashing for robust tampering detection},
	doi = {10.1109/TENCON.2015.7373018},
	abstract = {This paper proposes a novel multi-scale image hashing method by using the location-context information of the features generated by adaptive local feature extraction techniques. The adaptive local feature extraction method is proposed for more robust feature descriptors. The global hash is calculated to determine whether the received image has been maliciously tampered. The multi-scale hash is calculated to locate the tampered regions. Experimental results show that the proposed tampering detection scheme is very robust against the content-preserving attacks, including both common signal processing and geometric distortions.},
	booktitle = {{TENCON} 2015 - 2015 {IEEE} {Region} 10 {Conference}},
	author = {Yan, Cai-Ping and Pun, Chi-Man and Yuan, Xiao-Chen},
	month = nov,
	year = {2015},
	note = {ISSN: 2159-3450},
	keywords = {Adaptive Local Feature Extraction, Distortion, Feature extraction, Indexes, Location-Context Information, Multi-Scale Image Hashing, Robustness, Tampering Detection, Transform coding},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/QQF4PWH2/7373018.html:text/html;Yan et al_2015_Adaptive local feature based multi-scale image hashing for robust tampering.pdf:/Users/maodou/Zotero/storage/IHWPQBRM/Yan et al_2015_Adaptive local feature based multi-scale image hashing for robust tampering.pdf:application/pdf},
}

@inproceedings{biOverSegmentationBasedImage2015,
	title = {Over-{Segmentation} {Based} {Image} {Forgery} {Detection}},
	isbn = {94-6252-095-X},
	booktitle = {2015 {International} {Conference} on {Electronic} {Science} and {Automation} {Control}},
	publisher = {Atlantis Press},
	author = {Bi, Xiu-Li and Pun, Chi-Man and Yuan, Xiao-Chen},
	year = {2015},
	pages = {23--26},
}

@inproceedings{yuanFeatureBasedVideo2013,
	title = {Feature {Based} {Video} {Watermarking} {Resistant} to {Geometric} {Distortions}},
	doi = {10.1109/TrustCom.2013.92},
	abstract = {This paper proposes a digital video watermarking scheme which is robust to geometric distortions, such as rotation, scaling, and cropping. The watermark is embedded / extracted based on feature extraction and local Zernike transform in / from each selected frame. The feature extraction method called Adaptive Harris Detector is proposed by adopting and revising the traditional Harris Corner Detector, and the local Zernike moments-based method is raised for watermarking use. In each selected frame, the extracted circular patches are decomposed into a collection of binary patches with Bit-Plane Decomposition method. Magnitudes of the local Zernike moments are calculated by Zernike transform and modified to embed the watermarks. Experimental results show that the proposed watermarking scheme is robust against geometric distortions and meanwhile preserves the imperceptibility of the video. Furthermore, it outperforms comparable methods when tested under common signal processing attacks.},
	booktitle = {2013 12th {IEEE} {International} {Conference} on {Trust}, {Security} and {Privacy} in {Computing} and {Communications}},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	month = jul,
	year = {2013},
	note = {ISSN: 2324-9013},
	keywords = {Adaptive Harris Detector, Bit-Plane Decomposition, Detectors, Feature extraction, Feature Extraction, Local Zernike Transform, Mobile communication, Robustness, Signal processing, Transforms, Video Watermarking, Watermarking},
	pages = {763--767},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/XPMKILSA/6680912.html:text/html;Yuan_Pun_2013_Feature Based Video Watermarking Resistant to Geometric Distortions.pdf:/Users/maodou/Zotero/storage/TMRRG5J4/Yuan_Pun_2013_Feature Based Video Watermarking Resistant to Geometric Distortions.pdf:application/pdf},
}

@inproceedings{yuanGeometricInvariantDigital2012,
	title = {A {Geometric} {Invariant} {Digital} {Image} {Watermarking} {Scheme} {Based} on {Robust} {Feature} {Detector} and {Local} {Zernike} {Moments}},
	doi = {10.1109/CGIV.2012.17},
	abstract = {A robust and geometric invariant digital image watermarking scheme based on robust feature points detector and local Zernike transform is proposed in this paper. The robust feature points detector is proposed based on SIFT algorithm to extract circular patches. A local Zernike moments-based watermarking scheme is raised. Each extracted circular patch is decomposed into a collection of binary patches and Zernike transform is applied to the appointed binary patches. Experimental results show that the proposed scheme is very robust against geometric distortions and common signal processing.},
	booktitle = {Imaging and {Visualization} 2012 {Ninth} {International} {Conference} on {Computer} {Graphics}},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	month = jul,
	year = {2012},
	keywords = {Digital images, Feature extraction, Geometric Invariant, Local Zernike Transform, Robust Feature Points Detector, Robustness, SIFT, Signal processing, Signal processing algorithms, Transforms, Watermarking},
	pages = {53--56},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/QG5SX9HD/6298348.html:text/html;Yuan_Pun_2012_A Geometric Invariant Digital Image Watermarking Scheme Based on Robust Feature.pdf:/Users/maodou/Zotero/storage/9TGAX9YG/Yuan_Pun_2012_A Geometric Invariant Digital Image Watermarking Scheme Based on Robust Feature.pdf:application/pdf},
}

@inproceedings{punGeometricInvariantDigital2011,
	title = {Geometric {Invariant} {Digital} {Image} {Watermarking} {Scheme} {Based} on {Feature} {Points} {Detector} and {Histogram} {Distribution}},
	doi = {10.1109/TrustCom.2011.24},
	abstract = {A robust and geometric invariant digital image watermarking scheme based on SIFT Based Feature Points Detector (SIFTFPD) and histogram distribution is proposed in this paper. The SIFTFPD is proposed to extract geometric invariant feature points from the host image for watermark embedding; and the descriptor is generated subsequently. With the feature extraction procedure, the circular regions centered at the extracted feature points and with the given radius are defined as embedding regions. For watermark embedding, some pixels are moved to form a specific pattern in the intensity-level histogram distribution in each embedding region, to indicate the watermark. For watermark extraction, the embedded regions are generated with the descriptor and according to the intensity-level histogram distribution in each region, the watermark can be extracted. Experimental results show that the proposed scheme is very robust against geometric distortion such as rotation, scaling, cropping, and affine transformation; and common signal processing, such as JPEG compression, median filtering, and Gaussian low-pass filtering.},
	booktitle = {{2011IEEE} 10th {International} {Conference} on {Trust}, {Security} and {Privacy} in {Computing} and {Communications}},
	author = {Pun, Chi-Man and Yuan, Xiao-Chen and Chen, C. L. Philip},
	month = nov,
	year = {2011},
	note = {ISSN: 2324-9013},
	keywords = {Databases, Detectors, Distortion, Feature extraction, Feature Extraction, Geometric Invariant, Histogram Distribution, Histograms, Robustness, SIFT, Watermarking},
	pages = {166--172},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/UZFPSMBG/6120816.html:text/html;Pun et al_2011_Geometric Invariant Digital Image Watermarking Scheme Based on Feature Points.pdf:/Users/maodou/Zotero/storage/C2CVPW89/Pun et al_2011_Geometric Invariant Digital Image Watermarking Scheme Based on Feature Points.pdf:application/pdf},
}

@inproceedings{yuanInvariantDigitalImage2011,
	title = {Invariant {Digital} {Image} {Watermarking} {Using} {Adaptive} {Harris} {Corner} {Detector}},
	doi = {10.1109/CGIV.2011.22},
	abstract = {A robust and geometric invariant digital image watermarking scheme based on feature extraction and histogram distribution is proposed in this paper. The feature extraction method called Harris Corner Detector is adopted and revised by adjusting the response threshold value and ranking the response R value to extract feature points and thus define the regions for watermark data bits embedding and extraction. Each embedding region is a square matrix centering at the selected feature points. For watermark embedding, some pixels are moved to form a specific pattern in the intensity-level histogram distribution in each embedding region, indicating the watermark. For watermark extraction, the Adaptive Harris Corner Detector is adopted to restore the image to its original un-rotated position. According to the intensity-level histogram distribution in each embedded region, the watermark is extracted. Experimental results show that the proposed scheme is very robust against rotation, scaling, JPEG compression, median filtering, low-pass Gaussian filtering and also noise pollution.},
	booktitle = {Imaging and {Visualization} 2011 {Eighth} {International} {Conference} {Computer} {Graphics}},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	month = aug,
	year = {2011},
	keywords = {Detectors, Feature extraction, Feature Extraction, Filtering, Geometric Invariant, Harris Corner Detector, Histogram Distribution, Histograms, Robustness, Signal processing, Watermarking},
	pages = {109--113},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/7PNFJGRZ/6054097.html:text/html;Yuan_Pun_2011_Invariant Digital Image Watermarking Using Adaptive Harris Corner Detector.pdf:/Users/maodou/Zotero/storage/SM8FS7UA/Yuan_Pun_2011_Invariant Digital Image Watermarking Using Adaptive Harris Corner Detector.pdf:application/pdf},
}

@inproceedings{yuanDigitalImageWatermarking2010,
	title = {Digital image watermarking scheme based on histogram in {DWT} domain},
	abstract = {A robust and geometric invariant digital watermarking scheme for gray-level images is proposed in this paper. The scheme carries out watermark embedding and extraction based on histogram in DWT domain. For watermark embedding, the original image is decomposed into the approximation and details sub-bands. Pixels of the approximation sub-band are grouped into m blocks, each of which has the same number of intensity-levels, thus the block histogram is generated; with the block histogram, pixels are moved to form a specific pattern in the intensity-level histogram distribution, indicating the watermark. For watermark extraction, the watermarked image is decomposed into the approximation and details sub-bands; then the pixels in the approximation sub-band are grouped into blocks in the similar manner. According to the histogram distribution in each block, the watermark is extracted. Experimental results show that the proposed scheme is highly robust against JPEG compression, geometric attacks and some common signal processing.},
	booktitle = {6th {International} {Conference} on {Digital} {Content}, {Multimedia} {Technology} and its {Applications}},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	month = aug,
	year = {2010},
	keywords = {Cryptography, Discrete Wavelet Transform, Discrete wavelet transforms, Fractals, Geometric Invariant, Histogram, Image coding, Pixel, Robust Watermarking, Robustness, Transform coding},
	pages = {395--399},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/R4MGNA42/5568608.html:text/html;Yuan_Pun_2010_Digital image watermarking scheme based on histogram in DWT domain.pdf:/Users/maodou/Zotero/storage/LSXEF2ET/Yuan_Pun_2010_Digital image watermarking scheme based on histogram in DWT domain.pdf:application/pdf},
}

@inproceedings{punReversibleImageWatermarking2010,
	title = {Reversible image watermarking using integer transform on {Lifting} wavelet coefficients},
	abstract = {A novel reversible watermarking scheme based on 2-D Lifting wavelet transform, LWT2, integer transform and block linking method is presented in the paper. LWT2 produces coefficient subbands whose values are in integer form. The integer transform is then applied for embedding watermark bits. In addition, the simple and fast block linking method is used for indicating the embedding location. Experimental results show that our proposed method can achieve high capacity for image watermarking while preserve good image quality.},
	booktitle = {6th {International} {Conference} on {Digital} {Content}, {Multimedia} {Technology} and its {Applications}},
	author = {Pun, Chi-Man and Hemman, Nopporn and Yuan, Xiao-Chen},
	month = aug,
	year = {2010},
	keywords = {Bit rate, PSNR, Watermarking},
	pages = {390--394},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/FJR8X6RA/5568615.html:text/html;Pun et al_2010_Reversible image watermarking using integer transform on Lifting wavelet.pdf:/Users/maodou/Zotero/storage/CE7RK9P9/Pun et al_2010_Reversible image watermarking using integer transform on Lifting wavelet.pdf:application/pdf},
}

@inproceedings{punRobustBlockGrayLevel2009,
	title = {Robust {Block} and {Gray}-{Level} {Histogram} {Based} {Watermarking} {Scheme}},
	booktitle = {Pacific-{Rim} {Conference} on {Multimedia}},
	publisher = {Springer},
	author = {Pun, Chi-Man and Yuan, Xiaochen},
	year = {2009},
	pages = {590--601},
}

@inproceedings{liImageSegmentationbasedRobust2018,
	title = {Image segmentation-based robust feature extraction for color image watermarking},
	volume = {10615},
	booktitle = {Ninth {International} {Conference} on {Graphic} and {Image} {Processing} ({ICGIP} 2017)},
	publisher = {SPIE},
	author = {Li, Mianjie and Deng, Zeyu and Yuan, Xiaochen},
	year = {2018},
	pages = {358--364},
}

@inproceedings{yuanInvariantImageWatermarking2012,
	title = {Invariant {Image} {Watermarking} {Using} {Harris} {Feature} {Extraction} and {Zernike} {Moments}},
	booktitle = {{ISA} 2012},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	year = {2012},
}
