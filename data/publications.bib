
@article{liCDSDNUnsupervisedSensitivity2022,
	title = {{CD}-{SDN}: {Unsupervised} {Sensitivity} {Disparity} {Networks} for {Hyper}-{Spectral} {Image} {Change} {Detection}},
	volume = {14},
	number = {19},
	journal = {Remote Sensing},
	author = {Li, Jinlong and Yuan, Xiaochen and Li, Jinfeng and Huang, Guoheng and Li, Ping and Feng, Li},
	year = {2022},
	note = {ISBN: 2072-4292
Publisher: MDPI},
	pages = {4806},
}

@article{zhangBlindDualWatermarking2022,
	title = {Blind {Dual} {Watermarking} {Scheme} {Using} {Stucki} {Kernel} and {SPIHT} for {Image} {Self}-{Recovery}},
	volume = {10},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2022.3204865},
	abstract = {In this paper we propose a blind dual watermarking scheme using Set Partitioning in Hierarchical Trees (SPIHT) and Stucki Kernel halftone technique for the tamper detection and image self-recovery. The watermark consists of authentication bits for tampering area location and recovery bits for image restoration. We generate two recovery bits to ensure the high-quality recovery of the tampered image. The primary recovery bit is generated by the SPIHT encoding, and the secondary recovery bit is generated by the Stucki Kernel halftone technique. Then the authentication bit is generated based on the recovery bits. Before embedding the watermark, we shuffle the watermark bits through Arnold cat mapping and diagonal mapping to improve the security and quality of the restored image. LSB-based watermarking technique is used to embed the watermark into the original image to ensure the invisibility of the watermarked image. Experiments have been conducted on two datasets, BOW2 and USC-SIPI, and results show that the proposed scheme can achieve high restoration quality. Comparison with the existing works demonstrate the good performance and superiority of the proposed scheme.},
	journal = {IEEE Access},
	author = {Zhang, Qiyuan and Yuan, Xiaochen and Liu, Tong},
	year = {2022},
	note = {Conference Name: IEEE Access},
	keywords = {Authentication, Discrete wavelet transforms, Image coding, Watermarking, Kernel, Discrete cosine transforms, Arnold cat map, authentication bit, Image restoration, image self-recovery, Set partitioning in hierarchical trees (SPIHT), Stucki Kernel halftone technique},
	pages = {96100--96111},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/3TZK5Z3V/9878311.html:text/html;Zhang et al_2022_Blind Dual Watermarking Scheme Using Stucki Kernel and SPIHT for Image.pdf:/Users/maodou/Zotero/storage/76I36GZK/Zhang et al_2022_Blind Dual Watermarking Scheme Using Stucki Kernel and SPIHT for Image.pdf:application/pdf},
}

@article{chenRSchainDecentralizedReputationsharing2022,
	title = {{RS}-chain: a decentralized reputation-sharing framework for group-buying industry via hybrid blockchain},
	journal = {Cluster Computing},
	author = {Chen, Yungui and Feng, Li and Liang, Hong and Yao, Shumin and Tian, Liwei and Yuan, Xiaochen},
	year = {2022},
	note = {ISBN: 1573-7543
Publisher: Springer},
	pages = {1--16},
}

@article{liAlterationDetectionMultispectral2021,
	title = {Alteration {Detection} of {Multispectral}/{Hyperspectral} {Images} {Using} {Dual}-{Path} {Partial} {Recurrent} {Networks}},
	volume = {13},
	number = {23},
	journal = {Remote Sensing},
	author = {Li, Jinlong and Yuan, Xiaochen and Feng, Li},
	year = {2021},
	note = {ISBN: 2072-4292
Publisher: MDPI},
	pages = {4802},
}

@article{wangReinforcementLearningBasedOptimization2022,
	title = {Reinforcement {Learning}-{Based} {Optimization} for {Mobile} {Edge} {Computing} {Scheduling} {Game}},
	issn = {2471-285X},
	doi = {10.1109/TETCI.2022.3145694},
	abstract = {Task scheduling on edge computing servers is a critical concern affecting user experience. Current scheduling methods attain an overall appealing performance through centralized control. Nevertheless, forcing users to act based on a centralized control is impractical. Hence, this work suggests a game theory-based distributed edge computing server task scheduling model. The proposed method comprehensively considers the mobile device-server link quality and the server’s computing resource allocation and balances link quality and computing resources requirements when selecting edge computing servers. Furthermore, we develop a time series prediction algorithm based on IndRNN and LSTM to accurately predict link quality. Once Nash equilibrium is reached quickly through our proposed acceleration scheme, the proposed model provides various QoS for different priority users. The experimental results highlight that the developed solution provides differentiated services while optimizing computing resource scheduling and ensuring an approximate Nash equilibrium in polynomial time.},
	journal = {IEEE Transactions on Emerging Topics in Computational Intelligence},
	author = {Wang, Tingting and Lu, Bingxian and Wang, Wei and Wei, Wei and Yuan, Xiaochen and Li, Jianqing},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Emerging Topics in Computational Intelligence},
	keywords = {Task analysis, Computational modeling, 5G mobile communication, Delays, edge computing, game theory, Games, Mobile Computing, Processor scheduling, scheduling, Servers},
	pages = {1--10},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/C53M3VBM/9704867.html:text/html;Wang et al_2022_Reinforcement Learning-Based Optimization for Mobile Edge Computing Scheduling.pdf:/Users/maodou/Zotero/storage/69UR33GI/Wang et al_2022_Reinforcement Learning-Based Optimization for Mobile Edge Computing Scheduling.pdf:application/pdf},
}

@article{FANG2022295,
	title = {Detection of weak electromagnetic interference attacks based on fingerprint in {IIoT} systems},
	volume = {126},
	issn = {0167-739X},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X21003289},
	doi = {https://doi.org/10.1016/j.future.2021.08.020},
	abstract = {In Industrial Internet of Things (IIoT) systems, the intelligent devices are vulnerable to be attacked by weak Electromagnetic Interference (EMI), thereby threatening the security of the systems. Therefore, it is of great significance to investigate the weak EMI attack of IIoT systems. The different manufacturing processes and deployment environments make the intelligent devices carry different noises, called fingerprints, which are unchanged unless these intelligent devices are attacked. Hence, we can detect weak EMI attacks by judging whether the fingerprint of intelligent device has been changed, which is different from using professional detection equipment as in other methods. Based on the fingerprint of intelligent device, this paper proposes a highly efficient weak EMI attack detection method which is divided into three steps. First, the fingerprint is extracted by Linear Time-Invariant (LTI) model and Kalman algorithm. Second, according to the extracted fingerprint, a fusion model is designed to determine whether the device is attacked by weak EMI. In the fusion model, Feature Extraction Unit (FEU) combines with Long Short-Term Memory (LSTM) to improve the detection accuracy. Finally, an edge computing framework is proposed to enhance the efficiency of the method. The experimental results show that the detection accuracy and the efficiency of the proposed method are 5.2\% and 42.2\% higher than those of the state-of-the-art method, respectively.},
	journal = {Future Generation Computer Systems},
	author = {Fang, Kai and Wang, Tingting and Yuan, Xiaochen and Miao, Chunyu and Pan, Yuanyuan and Li, Jianqing},
	year = {2022},
	keywords = {Edge computing, EMI attack, FEU-LSTM, Fingerprint, IIoT},
	pages = {295--304},
}

@article{liFDTRFeatureDetector2021,
	title = {{FD}-{TR}: feature detector based on scale invariant feature transform and bidirectional feature regionalization for digital image watermarking},
	volume = {80},
	number = {21},
	journal = {Multimedia Tools and Applications},
	author = {Li, Mianjie and Yuan, Xiaochen},
	year = {2021},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {32197--32217},
}

@article{liuDualtamperdetectionMethodDigital2021a,
	title = {A dual-tamper-detection method for digital image authentication and content self-recovery},
	volume = {80},
	number = {19},
	journal = {Multimedia Tools and Applications},
	author = {Liu, Tong and Yuan, Xiaochen},
	year = {2021},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {29805--29826},
}

@article{liuAdaptiveFeatureCalculation2021b,
	title = {Adaptive {Feature} {Calculation} and {Diagonal} {Mapping} for {Successive} {Recovery} of {Tampered} {Regions}},
	volume = {31},
	issn = {1558-2205},
	doi = {10.1109/TCSVT.2020.3032455},
	abstract = {This article proposes an adaptive scheme for image tampered region localization and content recovery. To generate the watermark information comprised of the authentication data and recovery data, we firstly propose the Adaptive Authentication Feature Calculation algorithm to obtain the authentication data, which includes the information of block location and block feature. The DWT-based Block Feature Calculation method is then proposed to calculate the block feature, and the quantization method is employed to calculate the block location. The recovery data is composed of self-recovery bits and mapped-recovery bits. The self-recovery bits are obtained by the Set Partitioning in Hierarchical Trees encoding algorithm. For retrieving the damaged codes caused by tampering, we propose the Diagonal Mapping algorithm and apply it to the self-recovery bits, thus generating the mapped-recovery bits, to provide a guarantee of recovery data. Experimental results show the superior performance of the proposed scheme in terms of tamper detection and image recovery, by comparing with the state-of-the-art works. The results demonstrate that the proposed method shows efficiency in the adaptiveness, well localization, strong capability for image recovery, and the effectiveness of attack resistance.},
	number = {7},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	author = {Liu, Tong and Yuan, Xiaochen},
	month = jul,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Circuits and Systems for Video Technology},
	keywords = {Adaptive authentication feature calculation, Authentication, diagonal mapping, Discrete wavelet transforms, DWT-based block feature calculation, Image coding, Media, Partitioning algorithms, successive content self-recovery, tamper detection, Watermarking},
	pages = {2617--2630},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/B6G3PZ4X/9233407.html:text/html;Liu_Yuan_2021_Adaptive Feature Calculation and Diagonal Mapping for Successive Recovery of.pdf:/Users/maodou/Zotero/storage/8K3335T4/Liu_Yuan_2021_Adaptive Feature Calculation and Diagonal Mapping for Successive Recovery of.pdf:application/pdf},
}

@article{YUAN2021116038,
	title = {Gauss–{Jordan} elimination-based image tampering detection and self-recovery},
	volume = {90},
	issn = {0923-5965},
	url = {https://www.sciencedirect.com/science/article/pii/S0923596520301855},
	doi = {https://doi.org/10.1016/j.image.2020.116038},
	abstract = {This paper proposes a novel Gauss–Jordan elimination-based image tampering detection and self-recovery scheme, aiming at dealing with the problem of malicious tampering on digital images. To deal with the copy–move tampering which is challenging because the tampered region may contain the watermark information, we propose the Improved Check Bits Generation algorithm during watermark generation, to generate the check bits for tampering detection. Meanwhile, the recovery bits are reconstructed according to the fundamental of Gauss–Jordan Elimination, for purpose of image contents self-recovery. To improve the accuracy of detection and the quality of recovered images, we propose the Morphological Processing-Based Enhancement method and the Edge Extension preprocessing respectively during and after the tampering detection Finally, the Gauss–JordanElimination-Based Self-Recovery method is proposed to recover the damaged content mathematically on basis of the detected results. By employing the unchanged recovery bits which are embedded in the non-tampered region, the failure in recovery caused by the damaged recovery bits can be completely avoided. A large number of experiments have been conducted to show the very good performance of the proposed scheme. The precision, recall, and F1 score are calculated for evaluation of tampering detection, while the PSNR values are calculated for evaluation of image recovery. The comparisons with the state-of-the-art methods show that the proposed scheme shows the superiorities in terms of imperceptibility, security and recovery capability. The experimental result indicates the average PSNR of recovered image is 44.415dB.},
	journal = {Signal Processing: Image Communication},
	author = {Yuan, Xiaochen and Li, Xinhang and Liu, Tong},
	year = {2021},
	keywords = {Gauss–Jordan Elimination-Based Self-Recovery, Image tampering detection, Improved check bits generation, Morphological processing-based enhancement},
	pages = {116038},
}

@article{yuanSpatialDomainBasedNonlinear2020,
	title = {Spatial {Domain}-{Based} {Nonlinear} {Residual} {Feature} {Extraction} for {Identification} of {Image} {Operations}},
	volume = {10},
	number = {16},
	journal = {Applied Sciences},
	author = {Yuan, Xiaochen and Huang, Tian},
	year = {2020},
	note = {ISBN: 2076-3417
Publisher: MDPI},
	pages = {5582},
}

@article{liAdaptiveSegmentationbasedFeature2020,
	title = {Adaptive segmentation-based feature extraction and {S}-{STDM} watermarking method for color image},
	volume = {32},
	number = {13},
	journal = {Neural Computing and Applications},
	author = {Li, Mianjie and Yuan, Xiaochen},
	year = {2020},
	note = {ISBN: 1433-3058
Publisher: Springer},
	pages = {9181--9200},
}

@article{liQuaternionDiscreteFourier2020,
	title = {Quaternion {Discrete} {Fourier} {Transform}-{Based} {Color} {Image} {Watermarking} {Method} {Using} {Quaternion} {QR} {Decomposition}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.2987914},
	abstract = {In this paper, a new Quaternion Discrete Fourier Transform (QDFT)-based digital color image watermarking method is presented. In addition, the Quaternion QR (QQR) decomposition is applied in digital watermarking technology for the first time. First of all, the QDFT and QQR decomposition are performed on the host image, respectively, to acquire the scalar part of the quaternion matrix for watermark information embedding. After that, we divide the scalar part of the quaternion matrix generated by the QQR decomposition into blocks and calculate the entropy. The block with high entropy is selected to embed the watermark information. Then the watermark information is embedded into the extracted block using the quantization index modulation method. We conducted a large number of tests and experimental results indicate that the presented approach obtains excellent robustness against Scaling, Rotation, Median filtering, `Salt \& Pepper' noise, and JPEG Compression. Compared with the existing methods, the presented method achieves better performance.},
	journal = {IEEE Access},
	author = {Li, Mianjie and Yuan, Xiaochen and Chen, Hai and Li, Jianqing},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Watermarking, Transforms, Color, Matrix decomposition, Data mining, Entropy, quantization index modulation, quaternion discrete Fourier transform (QDFT), quaternion QR (QQR) decomposition, Quaternions, scalar part, Watermarking technology},
	pages = {72308--72315},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/NWIMC37Y/9066976.html:text/html;Li et al_2020_Quaternion Discrete Fourier Transform-Based Color Image Watermarking Method.pdf:/Users/maodou/Zotero/storage/Z2XZX5EW/Li et al_2020_Quaternion Discrete Fourier Transform-Based Color Image Watermarking Method.pdf:application/pdf},
}

@article{yuanGramSchmidtOrthogonalizationBased2020,
	title = {Gram–{Schmidt} {Orthogonalization}-{Based} {Audio} {Multiple} {Watermarking} {Scheme}},
	volume = {39},
	number = {8},
	journal = {Circuits, Systems, and Signal Processing},
	author = {Yuan, Xiaochen and Li, Mianjie},
	year = {2020},
	note = {ISBN: 1531-5878
Publisher: Springer},
	pages = {3958--3977},
}

@article{CHEN2019163,
	title = {Automatic multi-level in-exhale segmentation and enhanced generalized {S}-transform for wheezing detection},
	volume = {178},
	issn = {0169-2607},
	url = {https://www.sciencedirect.com/science/article/pii/S0169260719305048},
	doi = {https://doi.org/10.1016/j.cmpb.2019.06.024},
	abstract = {Background and objective Wheezing is a common symptom of patients caused by asthma and chronic obstructive pulmonary diseases. Wheezing detection identifies wheezing lung sounds and helps physicians in diagnosis, monitoring, and treatment of pulmonary diseases. Different from the traditional way to detect wheezing sounds using digital image process methods, automatic wheezing detection uses computerized tools or algorithms to objectively and accurately assess and evaluate lung sounds. We propose an innovative machine learning-based approach for wheezing detection. The phases of the respiratory sounds are separated automatically and the wheezing features are extracted accordingly to improve the classification accuracy. Methods To enhance the features of wheezing for classification, the Adaptive Multi-Level In-Exhale Segmentation (AMIE$_{\textrm{S}}$EG) is proposed to automatically and precisely segment the respiratory sounds into inspiratory and expiratory phases. Furthermore, the Enhanced Generalized S-Transform (EGST) is proposed to extract the wheezing features. The highlighted features of wheezing improve the accuracy of wheezing detection with machine learning-based classifiers. Results To evaluate the novelty and superiority of the proposed AMIE$_{\textrm{S}}$EG and EGST for wheezing detection, we employ three machine learning-based classifiers, Support Vector Machine (SVM), Extreme Learning Machine (ELM) and K-Nearest Neighbor (KNN), with public datasets at segment level and record level respectively. According to the experimental results, the proposed method performs the best using the KNN classifier at segment level, with the measured accuracy, sensitivity, specificity as 98.62\%, 95.9\% and 99.3\% in average respectively. On the other aspect, at record level, the three classifiers perform excellent, with the accuracy, sensitivity, specificity up to 99.52\%, 100\% and 99.27\% respectively. We validate the method with public respiratory sounds dataset. Conclusion The comparison results indicate the very good performance of the proposed methods for long-term wheezing monitoring and telemedicine.},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Chen, Hai and Yuan, Xiaochen and Li, Jianqing and Pei, Zhiyuan and Zheng, Xiaobin},
	year = {2019},
	keywords = {Adaptive Multi-Level In-Exhale Segmentation (AMIE$_{\textrm{S}}$EG), Enhanced Generalized S Transform, Feature enhancement, Wheezing detection},
	pages = {163--173},
}

@article{chenTripleClassificationRespiratorySounds2019,
	title = {Triple-{Classification} of {Respiratory} {Sounds} {Using} {Optimized} {S}-{Transform} and {Deep} {Residual} {Networks}},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2903859},
	abstract = {Digital respiratory sounds provide valuable information for telemedicine and smart diagnosis in an non-invasive way of pathological detection. As the typical continuous abnormal respiratory sound, wheeze is clinically correlated with asthma or chronic obstructive lung diseases. Meanwhile, the discontinuous adventitious crackle is clinically correlated with pneumonia, bronchitis, and so on. The detection and classification of both attract many studies for decades. However, due to the contained artifacts and constrained feature extraction methods, the reliability and accuracy of the classification of wheeze, crackle, and normal sounds need significant improvement. In this paper, we propose a novel method for the identification of wheeze, crackle, and normal sounds using the optimized S-transform (OST) and deep residual networks (ResNets). First, the raw respiratory sound is processed by the proposed OST. Then, the spectrogram of OST is rescaled for the Resnet. After the feature learning and classification are fulfilled by the ResNet, the classes of respiratory sounds are recognized. Because the proposed OST highlights the features of wheeze, crackle, and respiratory sounds, and the deep residual learning generates discriminative features for better recognition, this proposed method provides reliable access for respiratory disease-related telemedicine and E-health diagnosis. The experimental results show that the proposed OST and ResNet is excellent for the multi-classification of respiratory sounds with the accuracy, sensitivity, and specificity up to 98.79\%, 96.27\% and 100\%, respectively. The comparison results of the triple-classification of respiratory sounds indicate that the proposed method outperforms the deep-learning-based ensembling convolutional neural network (CNN) by 3.23\% and the empirical mode decomposition-based artificial neural network (ANN) by 4.63\%, respectively.},
	journal = {IEEE Access},
	author = {Chen, Hai and Yuan, Xiaochen and Pei, Zhiyuan and Li, Mianjie and Li, Jianqing},
	year = {2019},
	note = {Conference Name: IEEE Access},
	keywords = {Feature extraction, Transforms, Training, crackle and wheeze detection, Deep residual networks (ResNet), Diseases, Lung, optimized S-transform (OST), respiratory sounds classification, Spectrogram, Time-frequency analysis},
	pages = {32845--32852},
	file = {Chen et al_2019_Triple-Classification of Respiratory Sounds Using Optimized S-Transform and.pdf:/Users/maodou/Zotero/storage/NL3GFR8H/Chen et al_2019_Triple-Classification of Respiratory Sounds Using Optimized S-Transform and.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/RHXL2GPA/8663379.html:text/html},
}

@article{YUAN2018103,
	title = {Local multi-watermarking method based on robust and adaptive feature extraction},
	volume = {149},
	issn = {0165-1684},
	url = {https://www.sciencedirect.com/science/article/pii/S0165168418301051},
	doi = {https://doi.org/10.1016/j.sigpro.2018.03.007},
	abstract = {This paper proposes a local multi-watermarking method based on robust and adaptive feature extraction. The Robust and Adaptive Feature Detector based on DAISY Descriptor (RAF3D) is proposed to extract the feature regions of high robustness and stability. The multi-watermarking method is proposed to embed the multiple watermarks simultaneously into the same extracted feature region. In this way, the capacity will be flexible with either the number of feature regions or the number of watermarks. In the proposed method, the Gram–Schmidt process is applied to embed the watermarks in orthogonal spaces, which guarantees the multiple watermarks can be extracted independently. By repeatedly embedding the watermarks into the numerous feature regions, the success rate of watermark detection can be greatly strengthened. In addition, the local embedding strategy improves the imperceptibility of the watermarked image. Extensive experiments are conducted to evaluate the performance of the proposed scheme and the comparison with several existing methods demonstrate that the proposed scheme outperforms the existing methods in terms of the robustness against various attacks.},
	journal = {Signal Processing},
	author = {Yuan, Xiao-Chen and Li, Mianjie},
	year = {2018},
	keywords = {Gram–Schmidt process, Local multi-watermarking, Robust and adaptive feature detector},
	pages = {103--117},
}

@article{liDualTreeComplexWavelet2018,
	title = {Dual-{Tree} {Complex} {Wavelet} {Transform} {Based} {Audio} {Watermarking} {Using} {Distortion}-{Compensated} {Dither} {Modulation}},
	volume = {6},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2018.2876233},
	abstract = {This paper presents a local audio watermarking method based on the dual-tree complex wavelet transform (DT CWT) and distortion-compensated dither modulation (DC-DM). Specifically, we perform DT CWT on extracted audio segment, and embed the watermark signal in the decomposed low-pass coefficients. During the embedding process, the selected coefficients are block-divided into multiple host vectors, and the watermark signal is embedded into the selected set of host vectors by the dither modulation process. During the extraction process, the DC-DM is applied to generate the statistical differences, and the minimum distance decoding is employed to extract the watermark signal. Experimental results show that the proposed method is robust against common signal processing attacks and de-synchronization attacks, such as re-quantization, resampling, MP3 compression, cropping, and so on. Comparisons with the existing methods also show the superiority of our proposed method.},
	journal = {IEEE Access},
	author = {Li, Mianjie and Yuan, Xiaochen and Li, Jianqing},
	year = {2018},
	note = {Conference Name: IEEE Access},
	keywords = {Discrete wavelet transforms, Watermarking, Continuous wavelet transforms, Distortion-compensated dither modulation (DC-DM), Dual-tree complex wavelet transform (DT CWT), Flowcharts, local audio watermarking, minimum distance decoding, Modulation},
	pages = {60834--60842},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/ZL8G3FJ8/8492419.html:text/html;Li et al_2018_Dual-Tree Complex Wavelet Transform Based Audio Watermarking Using.pdf:/Users/maodou/Zotero/storage/BXWRYKSL/Li et al_2018_Dual-Tree Complex Wavelet Transform Based Audio Watermarking Using.pdf:application/pdf},
}

@article{hanRegFrameFastRecognition2018,
	title = {{RegFrame}: fast recognition of simple human actions on a stand-alone mobile device},
	volume = {30},
	number = {9},
	journal = {Neural Computing and Applications},
	author = {Han, Di and Li, Jianqing and Zeng, Zihua and Yuan, Xiaochen and Li, Wenting},
	year = {2018},
	note = {ISBN: 1433-3058
Publisher: Springer},
	pages = {2787--2793},
}

@article{biMultiscaleFeatureExtraction2018,
	title = {Multi-scale feature extraction and adaptive matching for copy-move forgery detection},
	volume = {77},
	number = {1},
	journal = {Multimedia Tools and Applications},
	author = {Bi, XiuLi and Pun, Chi-Man and Yuan, Xiao-Chen},
	year = {2018},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {363--385},
}

@article{punImageAlignmentBasedMultiRegion2017,
	title = {Image {Alignment}-{Based} {Multi}-{Region} {Matching} for {Object}-{Level} {Tampering} {Detection}},
	volume = {12},
	issn = {1556-6013, 1556-6021},
	url = {http://ieeexplore.ieee.org/document/7583645/},
	doi = {10.1109/TIFS.2016.2615272},
	abstract = {Tampering detection methods based on image hashing have been widely studied with continuous advancements. However, most existing models cannot generate object-level tampering localization results, because the forensic hashes attached to the image lack contour information. In this paper, we present a novel tampering detection model that can generate an accurate, object-level tampering localization result. First, an adaptive image segmentation method is proposed to segment the image into closed regions based on strong edges. Then, the color and position features of the closed regions are extracted as a forensic hash. Furthermore, a geometric invariant tampering localization model named image alignment-based multi-region matching (IAMRM) is proposed to establish the region correspondence between the received and forensic images by exploiting their intrinsic structure information. The model estimates the parameters of geometric transformations via a robust image alignment method based on triangle similarity; in addition, it matches multiple regions simultaneously by utilizing manifold ranking based on different graph structures and features. Experimental results demonstrate that the proposed IAMRM is a promising method for object-level tampering detection compared with the state-ofthe-art methods.},
	language = {en},
	number = {2},
	urldate = {2022-10-28},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Pun, Chi-Man and Yan, Caiping and Yuan, Xiao-Chen},
	month = feb,
	year = {2017},
	pages = {377--391},
	file = {Pun 等。 - 2017 - Image Alignment-Based Multi-Region Matching for Ob.pdf:/Users/maodou/Zotero/storage/GG3ED2K5/Pun 等。 - 2017 - Image Alignment-Based Multi-Region Matching for Ob.pdf:application/pdf},
}

@article{punRobustImageHashing2018,
	title = {Robust image hashing using progressive feature selection for tampering detection},
	volume = {77},
	number = {10},
	journal = {Multimedia Tools and Applications},
	author = {Pun, Chi-Man and Yan, Cai-Ping and Yuan, Xiao-Chen},
	year = {2018},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {11609--11633},
}

@article{yanQuaternionBasedImageHashing2016,
	title = {Quaternion-{Based} {Image} {Hashing} for {Adaptive} {Tampering} {Localization}},
	volume = {11},
	issn = {1556-6021},
	doi = {10.1109/TIFS.2016.2594136},
	abstract = {Image-hashing-based tampering detection methods have been widely studied with continuous advancements. However, most of existing models are designed for a specific tampering. In this paper, we propose a novel quaternion-based image hashing to detect almost all types of tampering, including color changing, copy move, splicing, and so on. First, the quaternion Fourier-Mellin transform is used to calculate the geometric hash to eliminate the influence of geometric distortions. Then, a new quaternion image construction method, which combines advantages of both color and structural features, is proposed to implement the quaternion Fourier transform to calculate the image feature hash to locate the tampered regions. The objective is to provide a reasonably short image hashing with good performance, i.e., being perceptually robust against various content-preserving attacks while capable of detecting and locating almost all types of tampering. Furthermore, an adaptive tampering localization algorithm is proposed based on clustering analysis to improve the detection accuracy. The experimental results show that the proposed tampering detection model outperforms the existing state-of-the-art models and is very robust against various content-preserving attacks.},
	number = {12},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Yan, Cai-Ping and Pun, Chi-Man and Yuan, Xiao-Chen},
	month = dec,
	year = {2016},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Authentication, Feature extraction, Transforms, Robustness, Splicing, Image color analysis, Quaternions, adaptive tampering localization, Image hashing, quaternion Fourier transform (QFT), quaternion Fourier-Mellin transform (QMMT)},
	pages = {2664--2677},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/KB5UBD32/7523392.html:text/html;Yan et al_2016_Quaternion-Based Image Hashing for Adaptive Tampering Localization.pdf:/Users/maodou/Zotero/storage/XK4E3SH6/Yan et al_2016_Quaternion-Based Image Hashing for Adaptive Tampering Localization.pdf:application/pdf},
}

@article{PUN2016195,
	title = {Multi-scale noise estimation for image splicing forgery detection},
	volume = {38},
	issn = {1047-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S1047320316300098},
	doi = {https://doi.org/10.1016/j.jvcir.2016.03.005},
	abstract = {Noise discrepancies in multiple scales are utilized as indicators for image splicing forgery detection in this paper. Specifically, the test image is initially segmented into superpixels of multiple scales. In each individual scale, noise level function, which reflects the relation between noise level and brightness of each segment, is computed. Those segments not constrained by the noise level function are regarded as suspicious regions. In the final step, pixels appears in suspicious regions of each scale, after necessary morphological processing, are marked as spliced region(s). The Optimal Parameter Combination Searching (OPCS) Algorithm is proposed to determine the optimal parameters during the process. Two datasets are created for training the optimal parameters and to evaluate the proposed scheme, respectively. The experimental results show that the proposed scheme is effective, especially for the multi-objects splicing. In addition, the proposed scheme is proven to be superior to the existing state-of-the-art method.},
	journal = {Journal of Visual Communication and Image Representation},
	author = {Pun, Chi-Man and Liu, Bo and Yuan, Xiao-Chen},
	year = {2016},
	keywords = {Multi-scale noise estimation, Noise level function, Optimal Parameter Combination Searching (OPCS), SLIC superpixels, Splicing forgery},
	pages = {195--206},
}

@article{BI2016226,
	title = {Multi-level dense descriptor and hierarchical feature matching for {Copy}–{Move} forgery detection},
	volume = {345},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025516000955},
	doi = {https://doi.org/10.1016/j.ins.2016.01.061},
	abstract = {In this paper, a Multi-Level Dense Descriptor (MLDD) extraction method and a Hierarchical Feature Matching method are proposed to detect copy–move forgery in digital images. The MLDD extraction method extracts the dense feature descriptors using multiple levels, while the extracted dense descriptor consists of two parts: the Color Texture Descriptor and the Invariant Moment Descriptor. After calculating the MLDD for each pixel, the Hierarchical Feature Matching method subsequently detects forgery regions in the input image. First, the pixels that have similar color textures are grouped together into distinctive neighbor pixel sets. Next, each pixel is matched with pixels in its corresponding neighbor pixel set through its geometric invariant moments. Then, the redundant pixels from previously generated matched pixel pairs are filtered out by the proposed Adaptive Distance and Orientation Based Filtering method. Finally, some morphological operations are applied to generate the final detected forgery regions. Experimental results show that the proposed scheme can achieve much better detection results compared with the existing state-of-the-art CMFD methods, even under various challenging conditions such as geometric transforms, JPEG compression, noise addition and down-sampling.},
	journal = {Information Sciences},
	author = {Bi, Xiuli and Pun, Chi-Man and Yuan, Xiao-Chen},
	year = {2016},
	keywords = {Color Texture Descriptor, Copy–Move Forgery Detection (CMFD), Hierarchical Feature Matching, Invariant Moment Descriptor, Multi-Level Dense Descriptor (MLDD)},
	pages = {226--242},
}

@article{YAN20161,
	title = {Multi-scale image hashing using adaptive local feature extraction for robust tampering detection},
	volume = {121},
	issn = {0165-1684},
	url = {https://www.sciencedirect.com/science/article/pii/S0165168415003709},
	doi = {https://doi.org/10.1016/j.sigpro.2015.10.027},
	abstract = {The main problem addressed in this paper is the robust tampering detection of the image received in a transmission under various content-preserving attacks. To this aim the multi-scale image hashing method is proposed by using the location-context information of the features generated by adaptive and local feature extraction techniques. The generated hash is attached to the image before transmission and analyzed at destination to filter out the geometric transformations occurred in the received image by image restoration firstly. Based on the restored image, the image authentication using the global and color hash component is performed to determine whether the received image has the same contents as the trusted one or has been maliciously tampered, or just different. After regarding the received image as being tampered, the tampered regions will be localized through the multi-scale hash component. Lots of experiments are conducted to indicate that our tampering detection scheme outperforms the existing state-of-the-art methods and is very robust against the content-preserving attacks, including both common signal processing and geometric distortions.},
	journal = {Signal Processing},
	author = {Yan, Cai-Ping and Pun, Chi-Man and Yuan, Xiao-Chen},
	year = {2016},
	keywords = {Adaptive Feature Point Detection, Image authentication, Multi-scale image hashing, Tampering detection},
	pages = {1--16},
}

@article{punImageForgeryDetection2015,
	title = {Image {Forgery} {Detection} {Using} {Adaptive} {Oversegmentation} and {Feature} {Point} {Matching}},
	volume = {10},
	issn = {1556-6021},
	doi = {10.1109/TIFS.2015.2423261},
	abstract = {A novel copy-move forgery detection scheme using adaptive oversegmentation and feature point matching is proposed in this paper. The proposed scheme integrates both block-based and keypoint-based forgery detection methods. First, the proposed adaptive oversegmentation algorithm segments the host image into nonoverlapping and irregular blocks adaptively. Then, the feature points are extracted from each block as block features, and the block features are matched with one another to locate the labeled feature points; this procedure can approximately indicate the suspected forgery regions. To detect the forgery regions more accurately, we propose the forgery region extraction algorithm, which replaces the feature points with small superpixels as feature blocks and then merges the neighboring blocks that have similar local color features into the feature blocks to generate the merged regions. Finally, it applies the morphological operation to the merged regions to generate the detected forgery regions. The experimental results indicate that the proposed copy-move forgery detection scheme can achieve much better detection results even under various challenging conditions compared with the existing state-of-the-art copy-move forgery detection methods.},
	number = {8},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Pun, Chi-Man and Yuan, Xiao-Chen and Bi, Xiu-Li},
	month = aug,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Discrete wavelet transforms, Feature extraction, Forgery, Copy-move forgery detection, Digital images, Image color analysis, Image segmentation, adaptive over-segmentation, Adaptive Over-Segmentation, Copy-Move Forgery Detection, forgery region extraction, Forgery Region Extraction, local color feature, Local Color Feature},
	pages = {1705--1716},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/964UJLNB/7086315.html:text/html;Pun et al_2015_Image Forgery Detection Using Adaptive Oversegmentation and Feature Point.pdf:/Users/maodou/Zotero/storage/NST8Z3HL/Pun et al_2015_Image Forgery Detection Using Adaptive Oversegmentation and Feature Point.pdf:application/pdf},
}

@article{YUAN2015159,
	title = {Robust {Mel}-{Frequency} {Cepstral} coefficients feature detection and dual-tree complex wavelet transform for digital audio watermarking},
	volume = {298},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S002002551401130X},
	doi = {https://doi.org/10.1016/j.ins.2014.11.040},
	abstract = {A novel digital audio watermarking scheme based on robust Mel-Frequency Cepstral coefficients feature detection and dual-tree complex wavelet transform is proposed in this paper, which is similar as patchwork based methods that several segments are extracted from the host audio clip for watermarking use. The robust Mel-Frequency Cepstral coefficients feature detection method is proposed to extract the feature segments which should be relocated when the host audio signal attacked by various distortions including both the common audio signal processing and the conventional geometric distortions. With the robust feature segments, the approximate shift invariant transform dual-tree complex wavelet transform based watermarking method is proposed to embed the watermark into the DT CWT real low-pass coefficients of each segment, using the spread spectrum techniques. The linear correlation is calculated to judge the existence of the watermark during the watermark detection. Experimental results show that the proposed digital audio watermarking scheme based on robust Mel-Frequency Cepstral coefficients feature detection and dual-tree complex wavelet transform can achieve high robustness against the common audio signal processing, such as low-pass filtering, MP3 compression, echo addition, volume change, and normalization; and geometric distortions, such as resample Time-Scale Modification (TSM), pitch invariant TSM, and tempo invariant pitch shifting. In addition, the proposed audio watermarking scheme is resilient to Stir-mark for Audio, and it performs much better comparing with the existing state-of-the art methods.},
	journal = {Information Sciences},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man and Philip Chen, C.L.},
	year = {2015},
	keywords = {Dual-Tree Complex Wavelet Transform (DT CWT), Mel-Frequency Cepstral Coefficients, Pitch shifting, Stir-mark, Time-Scale Modification (TSM)},
	pages = {159--179},
}

@article{yuanFeatureExtractionLocal2014,
	title = {Feature extraction and local {Zernike} moments based geometric invariant watermarking},
	volume = {72},
	number = {1},
	journal = {Multimedia tools and applications},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	year = {2014},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {777--799},
}

@article{punHistogramModificationBased2015,
	title = {Histogram modification based image watermarking resistant to geometric distortions},
	volume = {74},
	number = {18},
	journal = {Multimedia Tools and Applications},
	author = {Pun, Chi-Man and Yuan, Xiao-Chen},
	year = {2015},
	note = {ISBN: 1573-7721
Publisher: Springer},
	pages = {7821--7842},
}

@article{punRobustSegmentsDetector2013,
	title = {Robust {Segments} {Detector} for {De}-{Synchronization} {Resilient} {Audio} {Watermarking}},
	volume = {21},
	issn = {1558-7924},
	doi = {10.1109/TASL.2013.2279312},
	abstract = {A robust feature points detector for invariant audio watermarking is proposed in this paper. The audio segments centering at the detected feature points are extracted for both watermark embedding and extraction. These feature points are invariant to various attacks and will not be changed much for maintaining high auditory quality. Besides, high robustness and inaudibility can be achieved by embedding the watermark into the approximation coefficients of Stationary Wavelet Transform (SWT) domain, which is shift invariant. The spread spectrum communication technique is adopted to embed the watermark. Experimental results show that the proposed Robust Audio Segments Extractor (RASE) and the watermarking scheme are not only robust against common audio signal processing, such as low-pass filtering, MP3 compression, echo addition, volume change, and normalization; and distortions introduced in Stir-mark benchmark for Audio; but also robust against synchronization geometric distortions simultaneously, such as resample time-scale modification (TSM) with scaling factors up to ±50\%, pitch invariant TSM by ±50\%, and tempo invariant pitch shifting by ±50\%. In general, the proposed scheme can well resist various attacks by the joint RASE and SWT approach, which performs much better comparing with the existing state-of-the art methods.},
	number = {11},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	author = {Pun, Chi-Man and Yuan, Xiao-Chen},
	month = nov,
	year = {2013},
	note = {Conference Name: IEEE Transactions on Audio, Speech, and Language Processing},
	keywords = {Watermarking, Feature extraction, Synchronization, Robustness, Digital audio players, Distortion, pitch shifting, Robust audio segments extractor (RASE), stationary wavelet transform (SWT), synchronization geometric distortions, time-scale modification (TSM)},
	pages = {2412--2424},
	file = {IEEE Xplore Abstract Record:/Users/maodou/Zotero/storage/6A9FDNPW/6583994.html:text/html;Pun_Yuan_2013_Robust Segments Detector for De-Synchronization Resilient Audio Watermarking.pdf:/Users/maodou/Zotero/storage/42RGCKTQ/Pun_Yuan_2013_Robust Segments Detector for De-Synchronization Resilient Audio Watermarking.pdf:application/pdf},
}

@article{YUAN20132087,
	title = {Geometric invariant watermarking by local {Zernike} moments of binary image patches},
	volume = {93},
	issn = {0165-1684},
	url = {https://www.sciencedirect.com/science/article/pii/S0165168413000418},
	doi = {https://doi.org/10.1016/j.sigpro.2013.01.024},
	abstract = {A novel digital image watermarking scheme based on feature extraction and local Zernike transform is proposed in this paper. We proposed a local Zernike moments based watermarking scheme where the watermarked image/region can be obtained directly by inverse Zernike Transform. An edge-based feature detector is proposed for local region extraction, with which, the distinct circular patch of given size can be extracted for watermark embedding and extraction. The extracted circular patch is decomposed into a collection of binary patches and Zernike transform is applied to the selected binary patches. Magnitudes of the local Zernike moments are calculated and modified to embed the watermarks. Experimental results show that the proposed watermarking scheme is very robust against geometric distortion such as rotation, scaling, cropping, and affine transformation; and common signal processing such as JPEG compression, median filtering, and low-pass Gaussian filtering.},
	number = {7},
	journal = {Signal Processing},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man and Chen, C.-L. Philip},
	year = {2013},
	keywords = {Feature extraction, Edge-based feature detector, Inverse Zernike transform, Local Zernike transform},
	pages = {2087--2095},
}

@article{yuanGeometricallyInvariantImage2012,
	title = {Geometrically invariant image watermarking based on feature extraction and {Zernike} transform},
	volume = {6},
	number = {2},
	journal = {International Journal of Security and its Applications},
	author = {Yuan, Xiao-Chen and Pun, Chi-Man},
	year = {2012},
	note = {ISBN: 1738-9976},
	pages = {217--222},
}

@article{punRobustGeometricInvariant2010,
	title = {Robust and geometric invariant watermarking scheme using block and gray-level histograms},
	author = {Pun, C.-M. and Yuan, X.-C.},
	year = {2010},
	note = {ISBN: 1975-9339},
}

@article{punGeometricInvariantDigital2010,
	title = {Geometric {Invariant} {Digital} {Image} {Watermarking} {Scheme} {Based} on {Histogram} in {DWT} {Domain}},
	volume = {5},
	doi = {10.4304/jmm.5.5.434-442},
	abstract = {A robust and geometric invariant digital watermarking scheme for gray-level images is proposed in this paper. The scheme carries out watermark embedding and extraction based on histogram in DWT domain. For watermark embedding, firstly, the original image is decomposed into the approximation and details sub-bands, of which, the approximation sub-band is used for watermark embedding. Pixels of the approximation subband are grouped into m blocks, each of which has the same number of gray-levels, thus the block histogram is generated; with the block histogram, the percentage of number of pixels in each block is calculated. Then some pixels in a block are moved to form a specific pattern in the gray-level histogram distribution, indicating the watermark. Finally, the embedded approximation sub-band and the other three details sub-bands are constructed into a watermarked image. For watermark extraction, firstly, the watermarked image is also decomposed into the approximation and details sub-bands; then the pixels in the approximation sub-band are grouped into blocks in the similar manner. According to the histogram distribution in each block, the watermark is extracted. Experimental results show that the proposed scheme is highly robust against JPEG compression, geometric attacks and some common signal processing, and it outperforms the existing methods in term of robustness.},
	journal = {Journal of Multimedia},
	author = {Pun, Chi-Man and Yuan, Xiaochen},
	month = oct,
	year = {2010},
	pages = {434--442},
}

@article{zhangCollaborativeMultifeatureExtraction2022,
	title = {Collaborative multi-feature extraction and scale-aware semantic information mining for medical image segmentation},
	volume = {67},
	issn = {0031-9155, 1361-6560},
	url = {https://iopscience.iop.org/article/10.1088/1361-6560/ac95f5},
	doi = {10.1088/1361-6560/ac95f5},
	abstract = {Objective. In recent years, methods based on U-shaped structure and skip connection have achieved remarkable results in many medical semantic segmentation tasks. However, the information integration capability of this structure is still limited due to the incompatibility of feature maps of encoding and decoding stages at corresponding levels and lack of extraction of valid information in the ﬁnal stage of encoding. This structural defect is particularly obvious in segmentation tasks with non-obvious, small and blurred-edge targets. Our objective is to design a novel segmentation network to solve the above problems. Approach. The segmentation network named Global Context-Aware Network is mainly designed by inserting a Multi-feature Collaboration Adaptation (MCA) module, a Scale-Aware Mining (SAM) module and an Edge-enhanced Pixel Intensity Mapping (Edge-PIM) into the U-shaped structure. Firstly, the MCA module can integrate information from all encoding stages and then effectively acts on the decoding stages, solving the problem of information loss during downsampling and pooling. Secondly, the SAM module can further mine information from the encoded high-level features to enrich the information passed to the decoding stage. Thirdly, EdgePIM can further reﬁne the segmentation results by edge enhancement. Main results. We newly collect Magnetic Resonance Imaging of Colorectal Cancer Liver Metastases (MRI-CRLM) dataset in different imaging sequences with non-obvious, small and blurred-edge liver metastases. Our method performs well on the MRI-CRLM dataset and the publicly available ISIC-2018 dataset, outperforming state-ofthe-art methods such as CPFNet on multiple metrics after boxplot analysis, indicating that it can perform well on a wide range of medical image segmentation tasks. Signiﬁcance. The proposed method solves the problem mentioned above and improved segmentation accuracy for non-obvious, small and blurred-edge targets. Meanwhile, the proposed visualization method Edge-PIM can make the edge more prominent, which can assist medical radiologists in their research work well.},
	language = {en},
	number = {20},
	urldate = {2022-11-02},
	journal = {Physics in Medicine \& Biology},
	author = {Zhang, Ruijun and He, Zixuan and Zhu, Jian and Yuan, Xiaochen and Huang, Guoheng and Pun, Chi-Man and Peng, Jianhong and Lin, Junzhong and Zhou, Jian},
	month = oct,
	year = {2022},
	pages = {205008},
	file = {Zhang 等 - 2022 - Collaborative multi-feature extraction and scale-a.pdf:/Users/maodou/Zotero/storage/WWKZTYZI/Zhang 等 - 2022 - Collaborative multi-feature extraction and scale-a.pdf:application/pdf},
}

@article{wangParallelMultipleWatermarking2022,
	title = {Parallel {Multiple} {Watermarking} {Using} {Adaptive} {Inter}-{Block} {Correlation}},
	journal = {Expert Systems with Applications},
	author = {Wang, Xingrun and Yuan, Xiaochen and Li, Mianjie and Sun, Ying and Tian, Jinyu and Guo, Hongfei and Li, Jianqing},
	year = {2022},
	note = {ISBN: 0957-4174
Publisher: Elsevier},
	pages = {119011},
}
